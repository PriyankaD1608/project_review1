# -*- coding: utf-8 -*-
"""Nesterov SGD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V-fNg8g6HTorbHWFK52ugM7rzHJhh_0I
"""

### METHOD 1 ###
import torch
import torch.nn as nn 
import torchvision.transforms as transforms
import torchvision.datasets as dsets
from torch.autograd import Variable

#STEP1
train_dataset = dsets.MNIST(root='./data',
                            train=True,
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset=dsets.MNIST(root='./data',
                         train=False,
                         transform=transforms.ToTensor())

#STEP2
len(train_dataset)
batch_size=100
n_iters=3000
num_epochs= n_iters/(len(train_dataset)/batch_size)
num_epochs=int(num_epochs)
num_epochs
train_loader=torch.utils.data.DataLoader(dataset=train_dataset,
                                          batch_size=batch_size,
                                          shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)

#STEP3
class FeedForwardNeuralNetModel(nn.Module):
  def __init__(self, input_size, hidden_size, num_classes):
     super(FeedForwardNeuralNetModel, self).__init__()
     self.fc1= nn.Linear(input_dim,hidden_dim)#linearity

     self.relu= nn.ReLU()#non-linear function

     self.fc2= nn.Linear(hidden_dim, output_dim)#linearfunction(readout)

  def forward(self, x):
    out=self.fc1(x) #Linear1

    out= self.relu(out)#NonLinear1

    out=self.fc2(out)#Linear2(readout)
    return out

#STEP4
input_dim=28*28
output_dim=10
hidden_dim=100

model = FeedForwardNeuralNetModel(input_dim, hidden_dim, output_dim)

#For GPU model
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model.to(device)

#STEP5
criterion = nn.CrossEntropyLoss()

#STEP6
learning_rate = 0.1

optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)

#STEP7
iter=0
for epoch in range(num_epochs):
  for i,(images,labels) in enumerate(train_loader):

    #for GPU model
    images = images.view(-1, 28*28).requires_grad_().to(device)
    labels = labels.to(device)

    #clear gradients w.r.t parameters
    optimizer.zero_grad()
    #forward pass to get outputs/logits
    outputs=model(images)
    #calculating loss
    loss=criterion(outputs,labels)
    #getting gradients w.r.t parameters
    loss.backward()
    #updating parameters
    optimizer.step()
    iter+=1
    if iter%500==0:
     #calculate accuracy
     correct = 0
     total = 0
     #iterate through test_dataset
     for images,labels in test_loader:

       #  USE GPU FOR MODEL  #
       images = images.view(-1, 28*28).requires_grad_().to(device)

       #forward pass only to get logits/output
       outputs=model(images)
       #get predictions from maxiumum value
       _, predicted=torch.max(outputs.data,1)
       #total number of labels
       total+=labels.size(0)
       #total number of correct predictions
       correct+=(predicted==labels).sum()

       #  USE GPU FOR MODEL  
       # Total correct predictions
       if torch.cuda.is_available():
          correct += (predicted.cpu() == labels.cpu()).sum()
       else:
          correct += (predicted == labels).sum()

     accuracy = 100 * correct / total
     print('Iterations:{}. Loss{}. Accuracy:{}'.format(iter, loss.item(), accuracy))

